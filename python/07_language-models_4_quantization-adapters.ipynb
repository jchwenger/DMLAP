{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvP-6e9k6zkB"
   },
   "source": [
    "# Language models 2 | Quantisation & Parameter-Efficient Finetuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqOrFZh5CQrV"
   },
   "source": [
    "Modified and augmented from this original Notebook [here](https://github.com/huggingface/notebooks/blob/main/peft/gemma_7b_english_quotes.ipynb), used in [this blog post](https://huggingface.co/blog/gemma-peft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2rV0wXJMzXL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Huggingface login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3QIjlRQMzXM"
   },
   "source": [
    "For some models and datasets, and if you want to push your model to HF (same as GitHub, but for models) you need to be logged into your HF account.\n",
    "\n",
    "For that, you need to create an account [here](https://huggingface.co/) and then to ['/settings/tokens'](https://huggingface.co/settings/tokens) to create an access token.\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "from huggingface_hub import notebook_login\n",
    "if not (Path.home()/'.huggingface'/'token').exists():\n",
    "    notebook_login()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxjjN78WCwnY"
   },
   "source": [
    "## LLMs on Consumer-grade Hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48dXGBp8C10m"
   },
   "source": [
    "### 1. Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az3WbUh9C3_K"
   },
   "source": [
    "Quantization is the set of techniques that transform the numbers used in models (weights and biases) from their original format (say, `float32`) into ones that take much less memory.\n",
    "\n",
    "The main rule of thumb is: there is a trade-off between *memory* (more quantization takes less, which is good) and *quality* (more quantization degrades the model abilities, which is bad).\n",
    "\n",
    "For guides, see:\n",
    "- the ['Overview'](https://huggingface.co/docs/transformers/en/quantization/overview) in the `Transformers` library docs, and\n",
    "- the ['BitsandBytes'](https://huggingface.co/docs/transformers/en/quantization/bitsandbytes) one, also there, and\n",
    "- ['Quantization'](https://huggingface.co/docs/peft/main/en/developer_guides/quantization) in the `Peft` library docs.\n",
    "- [This short course on Deeplearning.ai](https://learn.deeplearning.ai/courses/quantization-fundamentals), for people wanting to go real deep.\n",
    "\n",
    "Here's an example of how you would load a model in 8-bits:\n",
    "\n",
    "\n",
    "This goes even further, to 4-bits, that we use below. For full examples of this, check [this blog post](https://huggingface.co/blog/4bit-transformers-bitsandbytes), as well as the [inference](https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing) and [fine-tuning](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing) notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfQQQMRbG4mi",
    "outputId": "bf35a2c8-ebdc-4a29-a242-d8690cac6b5f"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "1e8e311eb4754a7c90ba2db151528f82",
      "b7da1d4a6f4b424bbdad2b0cb13e3cb2",
      "71937ca52abb49399ae372a10402937f",
      "c5c35ed5a8d745058d82d342cb915c34",
      "e39d477063a54e55ba6838fba1cc5c36",
      "ea7f1403f54342e582cf40453e02135b",
      "f170dcd409934a439bc5f596661385b8",
      "0422b0816cfc4b4faf865d4c48b96115",
      "7ab38edebc38495c8bc96b76643436eb",
      "42850dc0190f4099bfb1fc19c6443d93",
      "b37bfabfd2564f5ebcbedf512bec9dac"
     ]
    },
    "id": "DvS8K4pbD5FR",
    "outputId": "22d00c1e-f42c-4fe9-8f45-80d67b86a898"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# You can try and comment out this line...\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-7b\", # 7 billion parameters\n",
    "    # ...as well as this one, and witness the crash of your Colab session (out of RAM)\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wONGM4yDypY"
   },
   "source": [
    "### 2. LoRAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m8fiCJfD0pF"
   },
   "source": [
    "**LoRA** stands for \"[Low-Rank Adaptation (for Large Language Models](https://arxiv.org/abs/2106.09685))\". This is a set of techniques that leverages linear algebra to replace large weight matrices by smaller ones, and then merges the results, allowing users to train only \"patches\" (in HF they are called _adapters_). As often happens in this field, this sparked a wave of interest, leading to many different techniques (see [here](https://huggingface.co/docs/peft/main/en/conceptual_guides/adapter) for some of them).\n",
    "\n",
    "![LoRA illustration](https://cdn-lfs.hf.co/datasets/huggingface/documentation-images/4313422c5f2755897fb8ddfc5b99251358f679647ec0f2d120a3f1ff060defe7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27lora_diagram.png%3B+filename%3D%22lora_diagram.png%22%3B&response-content-type=image%2Fpng&Expires=1731883940&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTg4Mzk0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9kYXRhc2V0cy9odWdnaW5nZmFjZS9kb2N1bWVudGF0aW9uLWltYWdlcy80MzEzNDIyYzVmMjc1NTg5N2ZiOGRkZmM1Yjk5MjUxMzU4ZjY3OTY0N2VjMGYyZDEyMGEzZjFmZjA2MGRlZmU3P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=fOIer2uHVZAr2LmQmw%7E%7Es16CV7Y8KOi3n%7E5rmtg6NtiW12gHiJQPMpnm681nVMqZCKLpy95QSKbljUq6h5jOFg1fU80aTVuyX9oajdan3-1sqlydDWoGINOYmPtowfUaEWPlo4Kka%7EO%7EbZZ0VBJu7l63z%7EyvtKnT8LhGiuV4pA87pKZnuIk7YnwI6VdOCR9%7EkTyswl2UobJgmWEnvFTD6ap44lEOGWQjj58XhNINmRfDJznKJWnF%7E86hVXTajN4h8gEdJzQz6qXXGbbbxzDHQjujJZmKffHHzHOANsRNUhlTaDBRvkK4OHUt-zpyMMf6uSHjudK05OM12xxe9TO6hg__&Key-Pair-Id=K3RPWS32NSSJCE)\n",
    "\n",
    "([source](https://huggingface.co/docs/peft/main/en/developer_guides/lora#merge-lora-weights-into-the-base-model))\n",
    "\n",
    "Imagine we have an LLM loaded, like the one above. How would we configure it to train using these memory-saving techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7vFYRQcHsmx",
    "outputId": "375eea8e-fba1-4b77-93a6-f9c2ce893359"
   },
   "outputs": [],
   "source": [
    "from peft import TaskType\n",
    "from peft import LoraConfig\n",
    "from peft import get_peft_model\n",
    "\n",
    "# We need a config (a rabbit hole in its own right)\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8, # rank, aka LoRA attention dimension\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config=lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jg6EVYKEIbz3"
   },
   "source": [
    "As you can see, if we trained now we would only fine-tune a *tiny* fraction of all parameters!\n",
    "\n",
    "What is great about this is that you can now train only this fraction of the weights, this 'adapter', and save only that locally or to the Huggingface Hub, and whenever you or someone else downloads it, the library will automatically fetch the base model and merge the adapter!\n",
    "\n",
    "For more on these techniques, see:\n",
    "- the ['Quicktour'](https://huggingface.co/docs/peft/main/en/quicktour), and\n",
    "- ['Configurations and models'](https://huggingface.co/docs/peft/main/en/tutorial/peft_model_config), as well as\n",
    "- ['Integrations'](https://huggingface.co/docs/peft/main/en/tutorial/peft_integrations).\n",
    "\n",
    "Now, let's clear things up for our next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8apgMnaMKH8n"
   },
   "outputs": [],
   "source": [
    "# clear our memory (it takes a little while)\n",
    "import gc\n",
    "import time\n",
    "\n",
    "del quantization_config, model, lora_config, peft_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQr2df1wMKDw"
   },
   "source": [
    "## Two training examples (Quantized + LoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-fVR6TzOb66"
   },
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUY4wRcLNIhC"
   },
   "source": [
    "#### Install & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzHHbo03MWTD"
   },
   "source": [
    "In this example, the authors use a new, higher level library for training called [tlr](https://huggingface.co/docs/trl/en/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-5gJk3W_s0RY",
    "outputId": "623e471d-eed3-452c-89a9-467f2881480c"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install bitsandbytes\n",
    "    !pip install peft\n",
    "    !pip install trl\n",
    "    !pip install accelerate\n",
    "    !pip install datasets\n",
    "    !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVEotZX8s-v6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "# Get cpu, gpu or mps device for training.\n",
    "# See: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#creating-models\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "from peft import LoraConfig\n",
    "\n",
    "from trl import SFTConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHBholaqNMOm"
   },
   "source": [
    "#### Model Loading & Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyGWGJWFhRPq"
   },
   "source": [
    "We will fine-tune [Google's Gemma](https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315), but you can have a look at other available recent models:\n",
    "- [Microsoft's Phi](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)\n",
    "- [Meta's Llama](https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf)\n",
    "- [Mistral](https://huggingface.co/mistralai)\n",
    "- [Falcon](https://huggingface.co/collections/tiiuae/falconmamba-7b-66b9a580324dd1598b0f6d4a)\n",
    "- many, many others, see the [Open LLM leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)\n",
    "\n",
    "\n",
    "[Here's](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending) where you would search for text generation models (note the many other options in the side bar).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f474b5c80fbf4cf69b1b8b80421721d4",
      "3de92b889b5840cab1e43acbdca253ae",
      "fa64e89df1fc4bc7b3a2c99486e40546",
      "30345e54722141299ac4f2b96e10c938",
      "af066f7a2a6e40c0af2bb7ef5c2edd47",
      "cdccff0865c94319bd69e432a86f9b06",
      "fa9318498e5544ab8923287197096dba",
      "ece8d986d4c144279e2917201a9fd460",
      "5ac4a3e805054c30a56185717901abc3",
      "b8610342f2e84e2c9fcd429bc66ac611",
      "49ca953303b642e6843da55990b618c3"
     ]
    },
    "id": "KqTg4pFsjx3-",
    "outputId": "d6e6cc2c-8114-4afb-836c-2f18e11154db"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"google/gemma-7b\"\n",
    "# 7 billion parameters! (there are also 2-3b models available: e.g. google/gemma-2-2b)\n",
    "# thanks to these techniques you can finetune these on a 15GB T4, but you\n",
    "# may still encounter memory issues (depending on dataset, batch size, etc.)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# this time we quantize in 4-bits\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map={\"\":0},\n",
    ")\n",
    "\n",
    "# this passed to the trainer further down, which applies it for us\n",
    "lora_config = LoraConfig(\n",
    "    r=8, # rank, aka LoRA attention dimension\n",
    "    # `target_modules` describes the matrices to be reduced (which ones should be\n",
    "    # chosen depends on the architecture, rule of thumb: follow what HF does...)\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTRZLQeoj-AA"
   },
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZqPYgVMNUCP"
   },
   "source": [
    "Let's test our model before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Msk610TVUGW",
    "outputId": "ae7c3db6-bbb7-4559-eabd-e41a86a009af"
   },
   "outputs": [],
   "source": [
    "text = \"Quote: Imagination\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9ecuuMTkTYo"
   },
   "source": [
    "### Fine-tuning on a specific dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uh9rAI1GOS_i"
   },
   "source": [
    "[Here](https://huggingface.co/datasets?modality=modality:text&format=format:text&sort=trending) is where you would search for other ready-made datasets.\n",
    "\n",
    "For more on the `datasets` library, see the [`Quickstart`](https://huggingface.co/docs/datasets/en/quickstart) and the tutorials (on the left-hand side bar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm97_5EWOQkJ"
   },
   "source": [
    "#### Example 1: English Quotes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8FbTsG1D5Ra"
   },
   "source": [
    "\n",
    "See the dataset page [here](https://huggingface.co/datasets/Abirate/english_quotes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPQSpLNAuubn"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"Abirate/english_quotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgcN130P7VZn",
    "outputId": "ed936c70-d9f4-426a-d65c-0670187d58b5"
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1O-R0t22-gQ",
    "outputId": "a0217253-cf38-4b6d-ad2c-3b873336ea1a"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "for i, d in enumerate(data[\"train\"]):\n",
    "    print(d.keys())\n",
    "    print(d[\"quote\"])\n",
    "    print(d[\"author\"])\n",
    "    print(d[\"tags\"])\n",
    "    print()\n",
    "    print(\"---\")\n",
    "    if n == i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya6gg_rmOtzY"
   },
   "source": [
    "The main point of using `SFTConfig` and `SFTTrainer` instead of the regular `TrainerConfig` and `Trainer` is to make it more high-level (_supposedly_ simpler), and also to allow you to define this `formatting_func`, which will affect the behaviour of your model. Making your model follow a certain format allows you to know how the generation is likely to go, which can help you then code functions around that (for instance, you could have a better idea when to cut off generation when reaching the end of an answer).\n",
    "\n",
    "You can have a look at ['Supervised Fine-tuning Trainer'](https://huggingface.co/docs/trl/en/sft_trainer) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123,
     "referenced_widgets": [
      "85dd520b852c4bad9af24fe4ac52bf72",
      "b1f89a7e2e4d40cd9a3cc5c9dd8fbcec",
      "fd402eb90c8845b29530a217a9defc12",
      "c1ee9a3f455446a5a4a6a363c61afd78",
      "6f06408fe24c432f92fb4b327e23c023",
      "60ad64b7730749dc802e871056cf5072",
      "c86065c49d384c12ae965e7b8ff1904e",
      "32153db5a54e41c686a6620bf53dc871",
      "5316a83d2d1643ca81839bb6df20c3d4",
      "0ff2fe3c24704c6dad19ee557988a416",
      "be5bb61c742a4f16a4b91651faaf87c9"
     ]
    },
    "id": "HFbR2FIgVfiT",
    "outputId": "02ab7ad8-d731-4417-cab4-9f96fc25fdb4"
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    text = f\"Quote: {example['quote'][0]}\\nAuthor: {example['author'][0]}\"\n",
    "    return [text]\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    max_seq_length=8192, # https://huggingface.co/docs/transformers/en/model_doc/gemma#transformers.GemmaConfig\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    max_steps=10,       # very few steps\n",
    "    learning_rate=2e-4, # low learning rate\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=[\"none\"] # we don't need to save the training wandb.ai\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPMTI_VZPidl"
   },
   "source": [
    "We train for very few steps (very much a trial and error process: too little and you don't see a difference, too much and your model loses its prior knowledge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "3ygtonQbEFzo",
    "outputId": "fa084ebd-91b3-4396-d120-c30b5add3954"
   },
   "outputs": [],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rscb5IvpPvAY"
   },
   "source": [
    "The one thing to note is that the model now follows the format produced by `formatting_func`:\n",
    "\n",
    "```\n",
    "Quote: ...\n",
    "Author ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5Mim0lNViwe",
    "outputId": "36396d98-5057-41b6-968d-b7c37ad057ed"
   },
   "outputs": [],
   "source": [
    "text = \"Quote: Imagination\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# the model starts being repetitive after that: changing the sampling\n",
    "# method using a generation config could help, see the other notebook!\n",
    "outputs = model.generate(**inputs, max_new_tokens=11)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AZS_ED29IDn"
   },
   "source": [
    "#### Example 2: Shakespeare again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCNmjEijD3r2"
   },
   "source": [
    "See the dataset page [here](https://huggingface.co/datasets/karpathy/tiny_shakespeare).\n",
    "\n",
    "I bring this dataset again because it's a typical example of the kind of work you might have to do when faced with a dataset that is not formatted exactly as we need.\n",
    "\n",
    "Before training, our model shouldn't sound particularly Shakespearean (the larger the model, the more it'll be able to pick up on the prompt straight away)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdxK7ldOERXs",
    "outputId": "77353131-2d6e-449c-e081-01dffaf786e4"
   },
   "outputs": [],
   "source": [
    "text = \"PETRUCHIO:\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "czx8qP6I9IDo"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "shak_data = load_dataset(\"karpathy/tiny_shakespeare\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXu10OiSSR8Q"
   },
   "source": [
    "The main issue with this dataset is that it only contains one long text for each split. Not only will it not yield batches, but it also will crash our GPU memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01DyRLD-SaCT",
    "outputId": "b30d8261-c270-465a-e087-faa41433af9a"
   },
   "outputs": [],
   "source": [
    "shak_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9NlDHnZIXKg",
    "outputId": "6decfac4-aa6b-416f-fb48-a8261d21a9f3"
   },
   "outputs": [],
   "source": [
    "for b in shak_data[\"train\"]:\n",
    "    print(b.keys())\n",
    "    print(len(b['text'][0]), len(b['text']))\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U0hnzJGShGe"
   },
   "source": [
    "Here's how we would turn that into a better format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNK_p_Ip_h5I"
   },
   "outputs": [],
   "source": [
    "# with ChatGPT 4o help\n",
    "def chunk_text(example, chunk_size=250):\n",
    "    text = example[\"text\"]\n",
    "    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return {\"text\": chunks}  # Returns a list of chunks\n",
    "\n",
    "def flatten_chunks(batch):\n",
    "    # Flatten list of chunks into separate rows\n",
    "    # (this in effect splits the text into letters, which will be re-merged\n",
    "    # into strings when batching happens with `batched=True`)\n",
    "    flat_text = [{\"text\": chunk} for chunks in batch[\"text\"] for chunk in chunks]\n",
    "    return {\"text\": [entry[\"text\"] for entry in flat_text]}\n",
    "\n",
    "chunked_shak_data = shak_data.map(chunk_text, batched=False)\n",
    "chunked_shak_data = chunked_shak_data.map(flatten_chunks, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSx4yJIpS876",
    "outputId": "b88e8383-17d2-4abc-cbb2-143a911ee0a5"
   },
   "outputs": [],
   "source": [
    "chunked_shak_data # num_rows is what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LatZLrkxACIF",
    "outputId": "c63ec3a0-838e-4ad0-9cbe-1d3a15e925c9"
   },
   "outputs": [],
   "source": [
    "for b in chunked_shak_data[\"train\"]:\n",
    "    print(b.keys())\n",
    "    print(len(b['text']))\n",
    "    print(b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123,
     "referenced_widgets": [
      "c71022c141f94f9a9c64f2eb4d574539",
      "8a61d6715e9d415bb5fe23e73f97cd21",
      "d3359e4db7cc4aeb81b8a2106287eab4",
      "3c97c6b5f0f74fdeb82cfa7e073c46c8",
      "2af0b9f0212b4590a34b9e03eb0c8602",
      "18e84bbaf39645a4b4cdd2fa610ac75e",
      "3975772ca39c494b86d4ef50acbfdab2",
      "a9ebac2e4a1e452a905150527ec4f4b9",
      "0492d65802384b96b88124e8aad1676d",
      "97aab33496c54b558a5727c2f1ead41a",
      "6c35c0bb10a84ab2ab7f7f2c4d96f8e5"
     ]
    },
    "id": "ULPAnP9K-vC1",
    "outputId": "f487cd5e-fda2-4669-9fef-cd6dc9ca6c6d"
   },
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    # this time we don't really need a template (could be fun to play with!)\n",
    "    return example['text']\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    max_seq_length=8192, # https://huggingface.co/docs/transformers/en/model_doc/gemma#transformers.GemmaConfig\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    max_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"shak_outputs\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=[\"none\"]\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=chunked_shak_data[\"train\"],\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    formatting_func=formatting_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "mr7bLKu7ECH1",
    "outputId": "81c9d865-4d9f-4303-b322-901df2fdf33a"
   },
   "outputs": [],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHBwPx_lGGwI",
    "outputId": "c4e4385e-665c-47d3-f32f-cf0d814c22ed"
   },
   "outputs": [],
   "source": [
    "text = \"PETRUCHIO:\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyrkcbUre9YQ"
   },
   "source": [
    "### Saving your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AJnOynnR8zI"
   },
   "source": [
    "There are two ways of saving your model. It can be using the `trainer` (this won't save the weights of the base model, since it's assumed that you will download those again from the HF Hub if needed):\n",
    "\n",
    "```python\n",
    "MODEL_DIR = \"jchwenger/gemma-2b-gpu-int4-lora-minshakespeare\"\n",
    "trainer.save_model(MODEL_DIR)\n",
    "```\n",
    "\n",
    "Or saving the individual components (entire model):\n",
    "```python\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "lora_config.save_pretrained(MODEL_DIR)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "J2rV0wXJMzXL",
    "xm97_5EWOQkJ",
    "0AZS_ED29IDn"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0422b0816cfc4b4faf865d4c48b96115": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0492d65802384b96b88124e8aad1676d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ff2fe3c24704c6dad19ee557988a416": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18e84bbaf39645a4b4cdd2fa610ac75e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e8e311eb4754a7c90ba2db151528f82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b7da1d4a6f4b424bbdad2b0cb13e3cb2",
       "IPY_MODEL_71937ca52abb49399ae372a10402937f",
       "IPY_MODEL_c5c35ed5a8d745058d82d342cb915c34"
      ],
      "layout": "IPY_MODEL_e39d477063a54e55ba6838fba1cc5c36"
     }
    },
    "2af0b9f0212b4590a34b9e03eb0c8602": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30345e54722141299ac4f2b96e10c938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8610342f2e84e2c9fcd429bc66ac611",
      "placeholder": "​",
      "style": "IPY_MODEL_49ca953303b642e6843da55990b618c3",
      "value": " 4/4 [01:38&lt;00:00, 22.36s/it]"
     }
    },
    "32153db5a54e41c686a6620bf53dc871": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3975772ca39c494b86d4ef50acbfdab2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c97c6b5f0f74fdeb82cfa7e073c46c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97aab33496c54b558a5727c2f1ead41a",
      "placeholder": "​",
      "style": "IPY_MODEL_6c35c0bb10a84ab2ab7f7f2c4d96f8e5",
      "value": " 4016/4016 [00:00&lt;00:00, 5501.20 examples/s]"
     }
    },
    "3de92b889b5840cab1e43acbdca253ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdccff0865c94319bd69e432a86f9b06",
      "placeholder": "​",
      "style": "IPY_MODEL_fa9318498e5544ab8923287197096dba",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "42850dc0190f4099bfb1fc19c6443d93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49ca953303b642e6843da55990b618c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5316a83d2d1643ca81839bb6df20c3d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5ac4a3e805054c30a56185717901abc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "60ad64b7730749dc802e871056cf5072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c35c0bb10a84ab2ab7f7f2c4d96f8e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f06408fe24c432f92fb4b327e23c023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71937ca52abb49399ae372a10402937f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0422b0816cfc4b4faf865d4c48b96115",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ab38edebc38495c8bc96b76643436eb",
      "value": 4
     }
    },
    "7ab38edebc38495c8bc96b76643436eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "85dd520b852c4bad9af24fe4ac52bf72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1f89a7e2e4d40cd9a3cc5c9dd8fbcec",
       "IPY_MODEL_fd402eb90c8845b29530a217a9defc12",
       "IPY_MODEL_c1ee9a3f455446a5a4a6a363c61afd78"
      ],
      "layout": "IPY_MODEL_6f06408fe24c432f92fb4b327e23c023"
     }
    },
    "8a61d6715e9d415bb5fe23e73f97cd21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18e84bbaf39645a4b4cdd2fa610ac75e",
      "placeholder": "​",
      "style": "IPY_MODEL_3975772ca39c494b86d4ef50acbfdab2",
      "value": "Map: 100%"
     }
    },
    "97aab33496c54b558a5727c2f1ead41a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9ebac2e4a1e452a905150527ec4f4b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af066f7a2a6e40c0af2bb7ef5c2edd47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1f89a7e2e4d40cd9a3cc5c9dd8fbcec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ad64b7730749dc802e871056cf5072",
      "placeholder": "​",
      "style": "IPY_MODEL_c86065c49d384c12ae965e7b8ff1904e",
      "value": "Map: 100%"
     }
    },
    "b37bfabfd2564f5ebcbedf512bec9dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7da1d4a6f4b424bbdad2b0cb13e3cb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea7f1403f54342e582cf40453e02135b",
      "placeholder": "​",
      "style": "IPY_MODEL_f170dcd409934a439bc5f596661385b8",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "b8610342f2e84e2c9fcd429bc66ac611": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be5bb61c742a4f16a4b91651faaf87c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1ee9a3f455446a5a4a6a363c61afd78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ff2fe3c24704c6dad19ee557988a416",
      "placeholder": "​",
      "style": "IPY_MODEL_be5bb61c742a4f16a4b91651faaf87c9",
      "value": " 2508/2508 [00:00&lt;00:00, 24614.01 examples/s]"
     }
    },
    "c5c35ed5a8d745058d82d342cb915c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42850dc0190f4099bfb1fc19c6443d93",
      "placeholder": "​",
      "style": "IPY_MODEL_b37bfabfd2564f5ebcbedf512bec9dac",
      "value": " 4/4 [01:50&lt;00:00, 25.30s/it]"
     }
    },
    "c71022c141f94f9a9c64f2eb4d574539": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8a61d6715e9d415bb5fe23e73f97cd21",
       "IPY_MODEL_d3359e4db7cc4aeb81b8a2106287eab4",
       "IPY_MODEL_3c97c6b5f0f74fdeb82cfa7e073c46c8"
      ],
      "layout": "IPY_MODEL_2af0b9f0212b4590a34b9e03eb0c8602"
     }
    },
    "c86065c49d384c12ae965e7b8ff1904e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdccff0865c94319bd69e432a86f9b06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3359e4db7cc4aeb81b8a2106287eab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9ebac2e4a1e452a905150527ec4f4b9",
      "max": 4016,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0492d65802384b96b88124e8aad1676d",
      "value": 4016
     }
    },
    "e39d477063a54e55ba6838fba1cc5c36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea7f1403f54342e582cf40453e02135b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ece8d986d4c144279e2917201a9fd460": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f170dcd409934a439bc5f596661385b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f474b5c80fbf4cf69b1b8b80421721d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3de92b889b5840cab1e43acbdca253ae",
       "IPY_MODEL_fa64e89df1fc4bc7b3a2c99486e40546",
       "IPY_MODEL_30345e54722141299ac4f2b96e10c938"
      ],
      "layout": "IPY_MODEL_af066f7a2a6e40c0af2bb7ef5c2edd47"
     }
    },
    "fa64e89df1fc4bc7b3a2c99486e40546": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ece8d986d4c144279e2917201a9fd460",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ac4a3e805054c30a56185717901abc3",
      "value": 4
     }
    },
    "fa9318498e5544ab8923287197096dba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd402eb90c8845b29530a217a9defc12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32153db5a54e41c686a6620bf53dc871",
      "max": 2508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5316a83d2d1643ca81839bb6df20c3d4",
      "value": 2508
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
